{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/likeaAI/ai_study/blob/main/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D%20CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tZDgP0ORDhTH"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets   import boston_housing , mnist , fashion_mnist\n",
    "from tensorflow.keras.models     import Sequential , clone_model , Model\n",
    "from tensorflow.keras.layers     import Dense , Activation , InputLayer , Flatten , Input , BatchNormalization , Dropout , Embedding\n",
    "\n",
    "# CNN\n",
    "from tensorflow.keras.layers     import Conv2D , MaxPooling2D , AveragePooling2D \n",
    "from tensorflow.keras            import optimizers  \n",
    "from tensorflow.keras.callbacks  import EarlyStopping , ModelCheckpoint , Callback\n",
    "from tensorflow.keras.optimizers import SGD , Adam , RMSprop\n",
    "\n",
    "# 이미지 로드 \n",
    "from tensorflow.keras.preprocessing import image \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 자연어 처리\n",
    "from tensorflow.keras.preprocessing.text          import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence      import pad_sequences\n",
    "\n",
    "from keras.utils.np_utils      import to_categorical\n",
    "\n",
    "from sklearn.datasets          import load_iris , load_breast_cancer , load_digits\n",
    "from sklearn.model_selection   import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "oH-Vov1eVfL5",
    "outputId": "489b6e63-4524-46e6-d56e-a9d6db177f05"
   },
   "outputs": [],
   "source": [
    "img = image.load_img('C:/Users/crid2/ml-data/test_dog.png' , target_size = (100,100))\n",
    "img\n",
    "\n",
    "# 이미지를 학습하기 위해서는 넘파이 배열로 변환해야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7TrIROpWpJ8",
    "outputId": "b2b3ae82-432b-4310-a0d8-ebc05c6f6cba"
   },
   "outputs": [],
   "source": [
    "print('rows - width , cols - height , channels - rgb')\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img , axis = 0) \n",
    "image_ = np.vstack([img]) \n",
    "image_.shape\n",
    "# rgb code가 있어서 채널이 3개다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UNa3LNSfXKDR",
    "outputId": "3c181b98-1085-4997-ff98-33e1a70e3943"
   },
   "outputs": [],
   "source": [
    "print('CNN - Convolution Neural Network 합성곱 신경망 - ')\n",
    "print('CNN 핵심 - 합성곱레이어와 풀링레이어')\n",
    "print('padding  - valid , same')\n",
    "print('filters     - 몇개의 필터를 이용할지를 결정 즉, 출력모양의 깊이')\n",
    "print('kernel_size - 연산을 수행할 때 원도우의 크기')\n",
    "print('strides     - 가로,세로로 움직이면서 내적 연산을 수행하는데 한번에 얼마나 움직일지를 결정')\n",
    "model = Sequential() \n",
    "\n",
    "model.add( Conv2D(input_shape = (10, 10, 3) , \n",
    "                  filters = 10 , \n",
    "                  kernel_size = (3,3) , \n",
    "                  strides = (1,1) , \n",
    "                  padding = 'same') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gehVQ_oviOJA"
   },
   "source": [
    "- CNN - Convolution Neural Network 합성공 신경망 - \n",
    "- CNN 핵심 - 합성곱레이어와 플링레이어 \n",
    "- padding - valid, smae \n",
    "- kernel_size - 연산을 수행할때 윈도우 크기 \n",
    "- strides - 가로 세로 움직이면서 내적 연산을 수행하는데 한번에 얼마나 움직일지를 결정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_-COaXpdbaF",
    "outputId": "57db7ee4-b354-47f8-eaa4-a47682457d32"
   },
   "outputs": [],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('풀링 - pooling ')\n",
    "print('원도우 내에서 출력의 최대값을 추출하는 맥스풀링, 평균값 뽑아내는 애버리지 풀링 - ')\n",
    "print()\n",
    "\n",
    "# model.add( MaxPooling2D(pool_size = (2,2) , strides=(1,1), padding = 'valid' ) )\n",
    "# print(model.output_shape)\n",
    "\n",
    "model.add( AveragePooling2D(pool_size = (2,2) , strides=(1,1), padding = 'valid' ) )\n",
    "print(model.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCkmxUzyjpiS",
    "outputId": "7cb7f080-138f-48f5-ecf8-74324b947b4e"
   },
   "outputs": [],
   "source": [
    "datasets = load_digits()\n",
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pl8KAneRlOiG",
    "outputId": "88674082-8681-4407-b488-15a5bf2b0150"
   },
   "outputs": [],
   "source": [
    "datasets.images[0].shape # 왜 채널이 없을까 흑백이라서 1차원으로 본다. 컬러풀은 3차원...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "TioepRSmlVJm",
    "outputId": "fbf1afc5-c8a2-45b3-b7a0-bb8789cfa156"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.imshow(datasets.images[0] , cmap = plt.cm.binary)\n",
    "plt.grid(False)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "UEX-9dejl9Ab"
   },
   "outputs": [],
   "source": [
    "X_data = datasets.images\n",
    "y_data = datasets.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KF7XLSYtmFrh",
    "outputId": "56dcb873-7b97-4721-9e25-02862f514c8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 8, 8), (1797,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xe2M1eQ5mLZW",
    "outputId": "190b0683-1bbf-4f94-ac37-d30bed208cbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = X_data.reshape(X_data.shape[0], X_data.shape[1] ,  X_data.shape[2], 1 )\n",
    "X_data.shape # 채널 1이 있어야 학습이 가능해서 위의 모양대로 reshape을 하였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HDHB5YPfmixJ",
    "outputId": "5fd476ea-6a15-41c3-c558-4c2b7addfba2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = to_categorical(y_data)\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_QFlHri5mubS",
    "outputId": "73967462-8f2c-4d80-97b4-7be314690b89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1bDk4XY9mzCg",
    "outputId": "26d26b0e-5271-4949-f202-75289953cfc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 8, 8, 1), (1797, 10))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape , y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 8, 8, 1), (360, 8, 8, 1), (1437, 10), (360, 10))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X_data , \n",
    "                                                       y_data , \n",
    "                                                       test_size    = 0.2 ,\n",
    "                                                       random_state = 111)\n",
    "\n",
    "X_train.shape , X_test.shape , y_train.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn 입력층 - \n",
      "shape -  (None, 6, 6, 10)\n"
     ]
    }
   ],
   "source": [
    "print('cnn 입력층 - ')\n",
    "mnist_cnn_model = Sequential()\n",
    "mnist_cnn_model.add( Conv2D(input_shape = (X_data.shape[1], X_data.shape[2], X_data.shape[3]) , \n",
    "                            filters = 10 , \n",
    "                            kernel_size = (3,3) , \n",
    "                            strides = (1,1) , \n",
    "                            padding = 'valid' , activation = 'relu') ) \n",
    "\n",
    "print('shape - ' , mnist_cnn_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn 풀링레이어 만들기 - \n",
      "(None, 3, 3, 10)\n"
     ]
    }
   ],
   "source": [
    "print('cnn 풀링레이어 만들기 - ')\n",
    "\n",
    "mnist_cnn_model.add( MaxPooling2D(pool_size = (2,2) , padding = 'valid' ) )\n",
    "print(mnist_cnn_model.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 90)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_cnn_model.add( Flatten() )\n",
    "mnist_cnn_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_cnn_model.add( Dense(50 , activation = 'relu'))\n",
    "mnist_cnn_model.add( Dense(10 , activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 10)          100       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 3, 3, 10)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 90)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                4550      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,160\n",
      "Trainable params: 5,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_cnn_model.compile(optimizer = Adam(learning_rate = 0.01), \n",
    "                      loss= 'categorical_crossentropy' , \n",
    "                      metrics=['accuracy'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "mnist_cnn_model_history = mnist_cnn_model.fit(X_train , y_train , epochs=100  , batch_size = 50 , validation_split = 0.2 , verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(mnist_cnn_model_history.history['accuracy']    , 's-', label='acc')\n",
    "plt.plot(mnist_cnn_model_history.history['val_accuracy'], 'd-', label='val_acc')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xticks(np.arange(100))\n",
    "plt.title('accuracy')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_cnn_model_eval = mnist_cnn_model.evaluate(X_test , y_test)\n",
    "mnist_cnn_model_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist 이용한 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99lqFP3noo72",
    "outputId": "9c3b1c84-28e5-4363-cae5-bc8587c6b222"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((60000, 28, 28), (10000, 28, 28)), ((60000,), (10000,)))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train,y_train),(X_test, y_test)= mnist.load_data()\n",
    "\n",
    "(X_train.shape, X_test.shape), (y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SZG8MCAGwtG6"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0] , X_train.shape[1] , X_train.shape[2], 1 )\n",
    "X_test = X_test.reshape(X_test.shape[0] , X_test.shape[1] , X_test.shape[2], 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jp7QVhtSxLlt",
    "outputId": "a8ac266a-9c39-442b-bcd8-cf68d887fd31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((60000, 28, 28, 1), (60000,)), ((10000, 28, 28, 1), (10000,)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, y_train.shape) , (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LgojPZIcxWPu"
   },
   "outputs": [],
   "source": [
    "# 데이터 전처리 - \n",
    "\n",
    "X_train, X_test = X_train/255 , X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GVB8pkBJxbLg",
    "outputId": "1aeed0a3-fb0a-40f3-d084-3d78f934c358"
   },
   "outputs": [],
   "source": [
    "\n",
    "mnist_cnn_model = Sequential()\n",
    "#1 \n",
    "mnist_cnn_model.add( Conv2D(input_shape = (X_train.shape[1],X_train.shape[2],X_train.shape[3]), \n",
    "                           filters = 32 , \n",
    "                           kernel_size= (3,3),\n",
    "                           strides = (1,1),\n",
    "                           padding = 'same' , activation= 'relu'))\n",
    "\n",
    "mnist_cnn_model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "\n",
    "#2\n",
    "mnist_cnn_model.add( Conv2D(input_shape = (X_train.shape[1],X_train.shape[2],X_train.shape[3]), \n",
    "                           filters = 64 , \n",
    "                           kernel_size= (3,3),\n",
    "                           strides = (1,1),\n",
    "                           padding = 'same' , activation= 'relu'))\n",
    "\n",
    "mnist_cnn_model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "#3 \n",
    "mnist_cnn_model.add( Conv2D(input_shape = (X_train.shape[1],X_train.shape[2],X_train.shape[3]), \n",
    "                           filters = 64 , \n",
    "                           kernel_size= (3,3),\n",
    "                           strides = (1,1),\n",
    "                           padding = 'same' , activation= 'relu'))\n",
    "\n",
    "mnist_cnn_model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 4, 4, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN 입력층 생성 \n",
    "mnist_cnn_model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature extraction - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j1ywVGUFzpMQ",
    "outputId": "306512c9-60ac-42c8-da2e-42e56137c719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense 층 추가 - \n"
     ]
    }
   ],
   "source": [
    "print('Dense 층 추가 - ')\n",
    "mnist_cnn_model.add( Flatten() )\n",
    "mnist_cnn_model.add( Dense(units = 512) )\n",
    "mnist_cnn_model.add( Activation('relu') )\n",
    "mnist_cnn_model.add( Dense(units = 256) )\n",
    "mnist_cnn_model.add( Activation('relu') )\n",
    "mnist_cnn_model.add( Dense(units = 128) )\n",
    "mnist_cnn_model.add( Activation('relu') )\n",
    "mnist_cnn_model.add( Dense(units = 64) )\n",
    "mnist_cnn_model.add( Activation('relu') )\n",
    "\n",
    "mnist_cnn_model.add( Dense(units = 10) )\n",
    "mnist_cnn_model.add( Activation('softmax') )\n",
    "\n",
    "\n",
    "# mnist_cnn_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuzpX6850V4n",
    "outputId": "beb44f4c-4512-4913-c6e8-d19d797b984c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 753,674\n",
      "Trainable params: 753,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GIFKe5NpxbhN"
   },
   "outputs": [],
   "source": [
    "mnist_cnn_model.compile(optimizer = Adam(learning_rate = 0.01), \n",
    "                      loss= 'sparse_categorical_crossentropy' , \n",
    "                      metrics=['accuracy'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3pmYPyXxbj4",
    "outputId": "0ce8c058-b94a-4165-c7f5-01752df375ff"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/device:GPU:0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      2\u001b[0m     mnist_cnn_model_history \u001b[38;5;241m=\u001b[39m mnist_cnn_model\u001b[38;5;241m.\u001b[39mfit(X_train , y_train , epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m  , batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m , validation_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m , verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "mnist_cnn_model_history = mnist_cnn_model.fit(X_train , y_train , epochs=12  , batch_size = 50 , validation_split = 0.2 , verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1tJARHSxbmW"
   },
   "outputs": [],
   "source": [
    "mnist_cnn_model_eval = mnist_cnn_model.evaluate(X_test, y_test)\n",
    "mnist_cnn_model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcWnY97IxbrG"
   },
   "outputs": [],
   "source": [
    "print('모델 저장')\n",
    "mnist_cnn_model.save('model-case.h12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPV6nP-Q3Juz"
   },
   "outputs": [],
   "source": [
    "print('모델 복원')\n",
    "loaded_model = load_model('model-case.h12')\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXZgZYJi3Jxa"
   },
   "outputs": [],
   "source": [
    "loss , acc = loaded_model.evaluate(X_test , y_test)\n",
    "print('loss - ' , loss)\n",
    "print('acc  - ' , acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 분류 (horse-or-human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 세트 경로 - \n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print('데이터 세트 경로 - ')\n",
    "train_horse_dir = 'C:/Users/crid2/ml-data/horse-or-human/horses'\n",
    "train_human_dir = 'C:/Users/crid2/ml-data/horse-or-human/humans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horse_fileName = os.listdir(train_horse_dir)\n",
    "train_human_fileName = os.listdir(train_human_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['horse01-0.png',\n",
       " 'horse01-1.png',\n",
       " 'horse01-2.png',\n",
       " 'horse01-3.png',\n",
       " 'horse01-4.png',\n",
       " 'horse01-5.png',\n",
       " 'horse01-6.png',\n",
       " 'horse01-7.png',\n",
       " 'horse01-8.png',\n",
       " 'horse01-9.png']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_horse_fileName[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['human01-00.png',\n",
       " 'human01-01.png',\n",
       " 'human01-02.png',\n",
       " 'human01-03.png',\n",
       " 'human01-04.png',\n",
       " 'human01-05.png',\n",
       " 'human01-06.png',\n",
       " 'human01-07.png',\n",
       " 'human01-08.png',\n",
       " 'human01-09.png']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_human_fileName[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 이미지 갯수 - \n",
      "horse len -  500\n",
      "human len -  527\n"
     ]
    }
   ],
   "source": [
    "print('총 이미지 갯수 - ')\n",
    "print('horse len - ' , len(train_horse_fileName))\n",
    "print('human len - ' , len(train_human_fileName))\n",
    "\n",
    "# 'C:/Users/crid2/ml-data/horse-or-human' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_img_generator = ImageDataGenerator(rescale=1/255)\n",
    "train_generator = train_img_generator.flow_from_directory(\n",
    "    'C:/Users/crid2/ml-data/horse-or-human' , \n",
    "    target_size = (300, 300) , \n",
    "    batch_size  = 128 ,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_model() :\n",
    "  img_model = Sequential()\n",
    "\n",
    "  img_model.add( Conv2D(input_shape = (300, 300, 3) , filters = 16 , kernel_size = (3,3) , strides = (1,1) , padding = 'valid') )\n",
    "  img_model.add( Activation('relu'))\n",
    "  img_model.add( MaxPooling2D(pool_size = (2,2) , padding = 'valid' ) )\n",
    "  img_model.add( Dropout(0.25) )\n",
    "      \n",
    "  img_model.add( Conv2D(filters = 32 , kernel_size = (3,3) , strides = (1,1) , padding = 'valid') )\n",
    "  img_model.add( Activation('relu'))\n",
    "  img_model.add( MaxPooling2D(pool_size = (2,2) , padding = 'valid' ) )\n",
    "  img_model.add( Dropout(0.25) )\n",
    "\n",
    "  img_model.add( Conv2D(filters = 64 , kernel_size = (3,3) , strides = (1,1) , padding = 'valid') )\n",
    "  img_model.add( Activation('relu'))\n",
    "  img_model.add( MaxPooling2D(pool_size = (2,2) , padding = 'valid' ) )\n",
    "  img_model.add( Dropout(0.25) )\n",
    "\n",
    "  img_model.add( Conv2D(filters = 64 , kernel_size = (3,3) , strides = (1,1) , padding = 'valid') )\n",
    "  img_model.add( Activation('relu'))\n",
    "  img_model.add( MaxPooling2D(pool_size = (2,2) , padding = 'valid' ) )\n",
    "  img_model.add( Dropout(0.25) )\n",
    "\n",
    "  img_model.add( Flatten() )\n",
    "  img_model.add( Dense(units = 512) )\n",
    "  img_model.add( Activation('relu') )\n",
    "  img_model.add( Dropout(0.25) )\n",
    "  \n",
    "  img_model.add( Dense(units = 1) )\n",
    "  img_model.add( Activation('sigmoid') )\n",
    "\n",
    "  return img_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 298, 298, 16)      448       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 298, 298, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 149, 149, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 149, 149, 16)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 147, 147, 32)      4640      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 147, 147, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 73, 73, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 73, 73, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 71, 71, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 35, 35, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 35, 35, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 33, 33, 64)        36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 33, 33, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               8389120   \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,450,145\n",
      "Trainable params: 8,450,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = img_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crid2\\anaconda3\\envs\\tf01\\lib\\site-packages\\keras\\optimizer_v2\\rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = RMSprop(lr = 0.001), \n",
    "                      loss= 'binary_crossentropy' , \n",
    "                      metrics=['accuracy'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(train_generator , epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m , verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m , steps_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(train_generator , epochs = 15 , verbose = 1 , steps_per_epoch = 8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget --no-check-certificate \\\n",
    "# https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "# -O /tmp/cats_and_dogs_filtered.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m      3\u001b[0m upload_img \u001b[38;5;241m=\u001b[39m files\u001b[38;5;241m.\u001b[39mupload()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(upload_img)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "upload_img = files.upload()\n",
    "print(upload_img)\n",
    "print(upload_img.keys())\n",
    "\n",
    "for fn in upload_img.keys() :\n",
    "  print('file name - ' , fn )\n",
    "  path = '/content/'+fn\n",
    "  img = image.load_img(path , target_size = (300, 300))\n",
    "  x   = image.img_to_array(img) \n",
    "  x   = np.expand_dims(x , axis = 0 ) \n",
    "  image_ = np.vstack([x])\n",
    "\n",
    "  classes = model.predict(image_ , batch_size = 10 ) \n",
    "  print('pred - ' , classes[0])\n",
    "print('예측하기 - ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고양이 개 이미지 분류 실습하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "path = '/tmp/cats_and_dogs_filtered.zip' \n",
    "zip  = zipfile.ZipFile(path , 'r')\n",
    "\n",
    "zip.extractall('/tmp')\n",
    "zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNExk2q6OmR56uP23IiPkZh",
   "include_colab_link": true,
   "name": "Untitled4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
