{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/likeaAI/ai_study/blob/main/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D%20CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tZDgP0ORDhTH"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets   import boston_housing , mnist , fashion_mnist\n",
    "from tensorflow.keras.models     import Sequential , clone_model , Model\n",
    "from tensorflow.keras.layers     import Dense , Activation , InputLayer , Flatten , Input , BatchNormalization , Dropout , Embedding\n",
    "\n",
    "# CNN\n",
    "from tensorflow.keras.layers     import Conv2D , MaxPooling2D , AveragePooling2D \n",
    "from tensorflow.keras            import optimizers  \n",
    "from tensorflow.keras.callbacks  import EarlyStopping , ModelCheckpoint , Callback\n",
    "from tensorflow.keras.optimizers import SGD , Adam , RMSprop\n",
    "\n",
    "# 이미지 로드 \n",
    "from tensorflow.keras.preprocessing import image \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 자연어 처리\n",
    "from tensorflow.keras.preprocessing.text          import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence      import pad_sequences\n",
    "\n",
    "from keras.utils.np_utils      import to_categorical\n",
    "\n",
    "from sklearn.datasets          import load_iris , load_breast_cancer , load_digits\n",
    "from sklearn.model_selection   import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 13:09:01.624438: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-28 13:09:01.624511: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 13565933454999534174\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 5523394490116781644\n",
       " physical_device_desc: \"device: 0, name: METAL, pci bus id: <undefined>\"\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "oH-Vov1eVfL5",
    "outputId": "489b6e63-4524-46e6-d56e-a9d6db177f05"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/crid2/ml-data/test_dog.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/crid2/ml-data/test_dog.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m img\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/preprocessing/image.py:313\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.utils.load_img\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    278\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.preprocessing.image.load_img\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_img\u001b[39m(path, grayscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m, target_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    280\u001b[0m              interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    281\u001b[0m   \u001b[38;5;124;03m\"\"\"Loads an image into PIL format.\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m  Usage:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m      ValueError: if interpolation method is not supported.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrayscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras_preprocessing/image/utils.py:113\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pil_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not import PIL.Image. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    112\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe use of `load_img` requires PIL.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    114\u001b[0m     img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m color_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;66;03m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001b[39;00m\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;66;03m# convert it to an 8-bit grayscale image.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/crid2/ml-data/test_dog.png'"
     ]
    }
   ],
   "source": [
    "img = image.load_img('C:/Users/crid2/ml-data/test_dog.png' , target_size = (100,100))\n",
    "img\n",
    "\n",
    "# 이미지를 학습하기 위해서는 넘파이 배열로 변환해야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7TrIROpWpJ8",
    "outputId": "b2b3ae82-432b-4310-a0d8-ebc05c6f6cba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows - width , cols - height , channels - rgb\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrows - width , cols - height , channels - rgb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m img \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(\u001b[43mimg\u001b[49m)\n\u001b[1;32m      3\u001b[0m img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img , axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \n\u001b[1;32m      4\u001b[0m image_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([img]) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "print('rows - width , cols - height , channels - rgb')\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img , axis = 0) \n",
    "image_ = np.vstack([img]) \n",
    "image_.shape\n",
    "# rgb code가 있어서 채널이 3개다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UNa3LNSfXKDR",
    "outputId": "3c181b98-1085-4997-ff98-33e1a70e3943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN - Convolution Neural Network 합성곱 신경망 - \n",
      "CNN 핵심 - 합성곱레이어와 풀링레이어\n",
      "padding  - valid , same\n",
      "filters     - 몇개의 필터를 이용할지를 결정 즉, 출력모양의 깊이\n",
      "kernel_size - 연산을 수행할 때 원도우의 크기\n",
      "strides     - 가로,세로로 움직이면서 내적 연산을 수행하는데 한번에 얼마나 움직일지를 결정\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 13:09:02.164604: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-28 13:09:02.164651: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "print('CNN - Convolution Neural Network 합성곱 신경망 - ')\n",
    "print('CNN 핵심 - 합성곱레이어와 풀링레이어')\n",
    "print('padding  - valid , same')\n",
    "print('filters     - 몇개의 필터를 이용할지를 결정 즉, 출력모양의 깊이')\n",
    "print('kernel_size - 연산을 수행할 때 원도우의 크기')\n",
    "print('strides     - 가로,세로로 움직이면서 내적 연산을 수행하는데 한번에 얼마나 움직일지를 결정')\n",
    "model = Sequential() \n",
    "\n",
    "model.add( Conv2D(input_shape = (10, 10, 3) , \n",
    "                  filters = 10 , \n",
    "                  kernel_size = (3,3) , \n",
    "                  strides = (1,1) , \n",
    "                  padding = 'same') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gehVQ_oviOJA"
   },
   "source": [
    "- CNN - Convolution Neural Network 합성공 신경망 - \n",
    "- CNN 핵심 - 합성곱레이어와 플링레이어 \n",
    "- padding - valid, smae \n",
    "- kernel_size - 연산을 수행할때 윈도우 크기 \n",
    "- strides - 가로 세로 움직이면서 내적 연산을 수행하는데 한번에 얼마나 움직일지를 결정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_-COaXpdbaF",
    "outputId": "57db7ee4-b354-47f8-eaa4-a47682457d32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 10, 10, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "풀링 - pooling \n",
      "원도우 내에서 출력의 최대값을 추출하는 맥스풀링, 평균값 뽑아내는 애버리지 풀링 - \n",
      "\n",
      "(None, 9, 9, 10)\n"
     ]
    }
   ],
   "source": [
    "print('풀링 - pooling ')\n",
    "print('원도우 내에서 출력의 최대값을 추출하는 맥스풀링, 평균값 뽑아내는 애버리지 풀링 - ')\n",
    "print()\n",
    "\n",
    "# model.add( MaxPooling2D(pool_size = (2,2) , strides=(1,1), padding = 'valid' ) )\n",
    "# print(model.output_shape)\n",
    "\n",
    "model.add( AveragePooling2D(pool_size = (2,2) , strides=(1,1), padding = 'valid' ) )\n",
    "print(model.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCkmxUzyjpiS",
    "outputId": "7cb7f080-138f-48f5-ecf8-74324b947b4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = load_digits()\n",
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pl8KAneRlOiG",
    "outputId": "88674082-8681-4407-b488-15a5bf2b0150"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.images[0].shape # 왜 채널이 없을까 흑백이라서 1차원으로 본다. 컬러풀은 3차원...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "TioepRSmlVJm",
    "outputId": "fbf1afc5-c8a2-45b3-b7a0-bb8789cfa156"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAADx0lEQVR4nO3dQVFraRRG0Z+uZyBIQALBQiSAFSxEAxISK0RCQEIk5BmgYNJ12J1ea5g7+FIFu24VA87d9XpdQM8/v/0FgK+JE6LECVHihChxQtSfH57f5J9yj8fj6N7r6+vY1m63G9va7/djW5vNZmzrF9x99aE3J0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6J+OsdwkybPI6y11ufn59jW5XIZ27q/vx/bOhwOY1trrfX8/Dy69xVvTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0RlzjGcTqexrcnzCGutdT6fx7YeHh7Gtna73djW5O/HWs4xAN8QJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6Iyt1Iul8vY1uPj49jWWrP3SyZtt9vf/go3zZsTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUf/Lcwy73W5s65ZN/sw2m83YVoU3J0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6Iy5xgm/93+6XQa25o2eSLh/f19bOvl5WVsq8KbE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVF31+v1u+ffPvw3fXx8TE2t7XY7trXWWm9vb2Nbx+NxbOt8Po9t3fIJjbXW3VcfenNClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQlbmVMmnydslaa+33+7Gtp6ensa3D4TC2dePcSoH/EnFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFC1E/nGIBf4s0JUeKEKHFClDghSpwQJU6I+gs3YFLOQbhmtQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.imshow(datasets.images[0] , cmap = plt.cm.binary)\n",
    "plt.grid(False)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UEX-9dejl9Ab"
   },
   "outputs": [],
   "source": [
    "X_data = datasets.images\n",
    "y_data = datasets.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KF7XLSYtmFrh",
    "outputId": "56dcb873-7b97-4721-9e25-02862f514c8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 8, 8), (1797,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xe2M1eQ5mLZW",
    "outputId": "190b0683-1bbf-4f94-ac37-d30bed208cbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = X_data.reshape(X_data.shape[0], X_data.shape[1] ,  X_data.shape[2], 1 )\n",
    "X_data.shape # 채널 1이 있어야 학습이 가능해서 위의 모양대로 reshape을 하였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HDHB5YPfmixJ",
    "outputId": "5fd476ea-6a15-41c3-c558-4c2b7addfba2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = to_categorical(y_data)\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_QFlHri5mubS",
    "outputId": "73967462-8f2c-4d80-97b4-7be314690b89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1bDk4XY9mzCg",
    "outputId": "26d26b0e-5271-4949-f202-75289953cfc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 8, 8, 1), (1797, 10))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape , y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 8, 8, 1), (360, 8, 8, 1), (1437, 10), (360, 10))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X_data , \n",
    "                                                       y_data , \n",
    "                                                       test_size    = 0.2 ,\n",
    "                                                       random_state = 111)\n",
    "\n",
    "X_train.shape , X_test.shape , y_train.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn 입력층 - \n",
      "shape -  (None, 6, 6, 10)\n"
     ]
    }
   ],
   "source": [
    "print('cnn 입력층 - ')\n",
    "mnist_cnn_model = Sequential()\n",
    "mnist_cnn_model.add( Conv2D(input_shape = (X_data.shape[1], X_data.shape[2], X_data.shape[3]) , \n",
    "                            filters = 10 , \n",
    "                            kernel_size = (3,3) , \n",
    "                            strides = (1,1) , \n",
    "                            padding = 'valid' , activation = 'relu') ) \n",
    "\n",
    "print('shape - ' , mnist_cnn_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn 풀링레이어 만들기 - \n",
      "(None, 3, 3, 10)\n"
     ]
    }
   ],
   "source": [
    "print('cnn 풀링레이어 만들기 - ')\n",
    "\n",
    "mnist_cnn_model.add( MaxPooling2D(pool_size = (2,2) , padding = 'valid' ) )\n",
    "print(mnist_cnn_model.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 90)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_cnn_model.add( Flatten() )\n",
    "mnist_cnn_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_cnn_model.add( Dense(50 , activation = 'relu'))\n",
    "mnist_cnn_model.add( Dense(10 , activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 10)          100       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 3, 3, 10)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 90)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                4550      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,160\n",
      "Trainable params: 5,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_cnn_model.compile(optimizer = Adam(learning_rate = 0.01), \n",
    "                      loss= 'categorical_crossentropy' , \n",
    "                      metrics=['accuracy'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 13:09:06.001103: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-28 13:09:06.167295: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 15ms/step - loss: 2.3065 - accuracy: 0.4273 - val_loss: 0.9834 - val_accuracy: 0.7604\n",
      "Epoch 2/100\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.5304 - accuracy: 0.8520"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 13:09:06.555032: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4344 - accuracy: 0.8799 - val_loss: 0.2570 - val_accuracy: 0.9028\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.1590 - accuracy: 0.9452 - val_loss: 0.2334 - val_accuracy: 0.9236\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0977 - accuracy: 0.9695 - val_loss: 0.1486 - val_accuracy: 0.9444\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0809 - accuracy: 0.9730 - val_loss: 0.1598 - val_accuracy: 0.9340\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0526 - accuracy: 0.9826 - val_loss: 0.1875 - val_accuracy: 0.9340\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0478 - accuracy: 0.9835 - val_loss: 0.1124 - val_accuracy: 0.9653\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0312 - accuracy: 0.9904 - val_loss: 0.1677 - val_accuracy: 0.9375\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9965 - val_loss: 0.1462 - val_accuracy: 0.9444\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0357 - accuracy: 0.9896 - val_loss: 0.1626 - val_accuracy: 0.9583\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0162 - accuracy: 0.9965 - val_loss: 0.1172 - val_accuracy: 0.9618\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.0946 - val_accuracy: 0.9653\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.0888 - val_accuracy: 0.9722\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1326 - val_accuracy: 0.9653\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0087 - accuracy: 0.9965 - val_loss: 0.0842 - val_accuracy: 0.9722\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9688\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9722\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9688\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 9.3556e-04 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 0.9722\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 6.9529e-04 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9722\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 6.3115e-04 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9722\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 5.6768e-04 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 0.9722\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 5.3610e-04 - accuracy: 1.0000 - val_loss: 0.0799 - val_accuracy: 0.9722\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.9088e-04 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9722\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.8393e-04 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9722\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.4492e-04 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9722\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.0920e-04 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9722\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.8553e-04 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9722\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 3.6602e-04 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9722\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 3.5042e-04 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9722\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 3.4092e-04 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9722\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.1627e-04 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9722\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.0507e-04 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9722\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 2.8784e-04 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9722\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.8175e-04 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9722\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.6541e-04 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9722\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.6175e-04 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9722\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.4238e-04 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9722\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 2.3389e-04 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9722\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.2880e-04 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9722\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1761e-04 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9722\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.1557e-04 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9722\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.0430e-04 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9722\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9383e-04 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9722\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.8983e-04 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9722\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.8130e-04 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9722\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.7560e-04 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9722\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.6648e-04 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9722\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.6243e-04 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9722\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.5476e-04 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9722\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.5175e-04 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9722\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.4772e-04 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9722\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.4012e-04 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9722\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.3824e-04 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9722\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.3171e-04 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9722\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.2840e-04 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9722\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.2374e-04 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9722\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 9ms/step - loss: 1.2112e-04 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 0.9722\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.1754e-04 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9722\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.1319e-04 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9722\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.1027e-04 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9722\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.0562e-04 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9722\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.0293e-04 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9722\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.0214e-04 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9722\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 9.8496e-05 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9722\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 9.4776e-05 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9722\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 9.3453e-05 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9722\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 9.2337e-05 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9722\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 8.7468e-05 - accuracy: 1.0000 - val_loss: 0.0974 - val_accuracy: 0.9722\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 8.5141e-05 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9722\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 8.3270e-05 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9722\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 8.0232e-05 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9722\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 7.8917e-05 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9722\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 7.7646e-05 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9722\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 7.4897e-05 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9722\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 7.3661e-05 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9722\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 7.1372e-05 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9722\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 7.0007e-05 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9722\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 6.7857e-05 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9722\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 6.5859e-05 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9722\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 6.4547e-05 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9722\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 6.3449e-05 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9722\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 6.1901e-05 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9722\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 6.0177e-05 - accuracy: 1.0000 - val_loss: 0.0990 - val_accuracy: 0.9722\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 5.8615e-05 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9722\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 5.7729e-05 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9722\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 5.5921e-05 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9722\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 5.4799e-05 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9722\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 5.4684e-05 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9722\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 5.1710e-05 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9722\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 5.1304e-05 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9722\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 4.9991e-05 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9722\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 4.9693e-05 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9722\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 4.8429e-05 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9722\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.7066e-05 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9722\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 4.6139e-05 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9722\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.5006e-05 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9722\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.3897e-05 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9722\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 4.3090e-05 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9722\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.1987e-05 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9722\n"
     ]
    }
   ],
   "source": [
    "mnist_cnn_model_history = mnist_cnn_model.fit(X_train , y_train , epochs=100  , batch_size = 50 , validation_split = 0.2 , verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(mnist_cnn_model_history.history['accuracy']    , 's-', label='acc')\n",
    "plt.plot(mnist_cnn_model_history.history['val_accuracy'], 'd-', label='val_acc')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xticks(np.arange(100))\n",
    "plt.title('accuracy')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1386 - accuracy: 0.9806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13858336210250854, 0.9805555939674377]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_cnn_model_eval = mnist_cnn_model.evaluate(X_test , y_test)\n",
    "mnist_cnn_model_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist 이용한 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99lqFP3noo72",
    "outputId": "9c3b1c84-28e5-4363-cae5-bc8587c6b222"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((60000, 28, 28), (10000, 28, 28)), ((60000,), (10000,)))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train,y_train),(X_test, y_test)= mnist.load_data()\n",
    "\n",
    "(X_train.shape, X_test.shape), (y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "SZG8MCAGwtG6"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0] , X_train.shape[1] , X_train.shape[2], 1 )\n",
    "X_test = X_test.reshape(X_test.shape[0] , X_test.shape[1] , X_test.shape[2], 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jp7QVhtSxLlt",
    "outputId": "a8ac266a-9c39-442b-bcd8-cf68d887fd31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((60000, 28, 28, 1), (60000,)), ((10000, 28, 28, 1), (10000,)))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, y_train.shape) , (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "LgojPZIcxWPu"
   },
   "outputs": [],
   "source": [
    "# 데이터 전처리 - \n",
    "\n",
    "X_train, X_test = X_train/255 , X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GVB8pkBJxbLg",
    "outputId": "1aeed0a3-fb0a-40f3-d084-3d78f934c358"
   },
   "outputs": [],
   "source": [
    "\n",
    "mnist_cnn_model = Sequential()\n",
    "#1 \n",
    "mnist_cnn_model.add( Conv2D(input_shape = (X_train.shape[1],X_train.shape[2],X_train.shape[3]), \n",
    "                           filters = 32 , \n",
    "                           kernel_size= (3,3),\n",
    "                           strides = (1,1),\n",
    "                           padding = 'same' , activation= 'relu'))\n",
    "\n",
    "mnist_cnn_model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "\n",
    "#2\n",
    "mnist_cnn_model.add( Conv2D(input_shape = (X_train.shape[1],X_train.shape[2],X_train.shape[3]), \n",
    "                           filters = 64 , \n",
    "                           kernel_size= (3,3),\n",
    "                           strides = (1,1),\n",
    "                           padding = 'same' , activation= 'relu'))\n",
    "\n",
    "mnist_cnn_model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "#3 \n",
    "mnist_cnn_model.add( Conv2D(input_shape = (X_train.shape[1],X_train.shape[2],X_train.shape[3]), \n",
    "                           filters = 64 , \n",
    "                           kernel_size= (3,3),\n",
    "                           strides = (1,1),\n",
    "                           padding = 'same' , activation= 'relu'))\n",
    "\n",
    "mnist_cnn_model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 4, 4, 64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN 입력층 생성 \n",
    "mnist_cnn_model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature extraction - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j1ywVGUFzpMQ",
    "outputId": "306512c9-60ac-42c8-da2e-42e56137c719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense 층 추가 - \n"
     ]
    }
   ],
   "source": [
    "print('Dense 층 추가 - ')\n",
    "mnist_cnn_model.add( Flatten() )\n",
    "mnist_cnn_model.add( Dense(units = 512) )\n",
    "mnist_cnn_model.add( Activation('relu') )\n",
    "mnist_cnn_model.add( Dense(units = 256) )\n",
    "mnist_cnn_model.add( Activation('relu') )\n",
    "mnist_cnn_model.add( Dense(units = 128) )\n",
    "mnist_cnn_model.add( Activation('relu') )\n",
    "mnist_cnn_model.add( Dense(units = 64) )\n",
    "mnist_cnn_model.add( Activation('relu') )\n",
    "\n",
    "mnist_cnn_model.add( Dense(units = 10) )\n",
    "mnist_cnn_model.add( Activation('softmax') )\n",
    "\n",
    "\n",
    "# mnist_cnn_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuzpX6850V4n",
    "outputId": "beb44f4c-4512-4913-c6e8-d19d797b984c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 753,674\n",
      "Trainable params: 753,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "GIFKe5NpxbhN"
   },
   "outputs": [],
   "source": [
    "mnist_cnn_model.compile(optimizer = Adam(learning_rate = 0.01), \n",
    "                      loss= 'sparse_categorical_crossentropy' , \n",
    "                      metrics=['accuracy'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3pmYPyXxbj4",
    "outputId": "0ce8c058-b94a-4165-c7f5-01752df375ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "  1/960 [..............................] - ETA: 5:27 - loss: 2.3026 - accuracy: 0.1200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 13:09:29.994035: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "958/960 [============================>.] - ETA: 0s - loss: 2.3067 - accuracy: 0.1104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 13:09:40.342335: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 12s 12ms/step - loss: 2.3066 - accuracy: 0.1106 - val_loss: 2.3030 - val_accuracy: 0.1060\n",
      "Epoch 2/12\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 2.3022 - accuracy: 0.1121 - val_loss: 2.3042 - val_accuracy: 0.1060\n",
      "Epoch 3/12\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 2.3022 - accuracy: 0.1126 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 4/12\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 2.3021 - accuracy: 0.1115 - val_loss: 2.3026 - val_accuracy: 0.1060\n",
      "Epoch 5/12\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 2.3022 - accuracy: 0.1118 - val_loss: 2.3039 - val_accuracy: 0.1060\n",
      "Epoch 6/12\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 2.3022 - accuracy: 0.1128 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 7/12\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 2.3021 - accuracy: 0.1126 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 8/12\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 2.3022 - accuracy: 0.1104 - val_loss: 2.3032 - val_accuracy: 0.1060\n",
      "Epoch 9/12\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 2.3020 - accuracy: 0.1116 - val_loss: 2.3024 - val_accuracy: 0.1081\n",
      "Epoch 10/12\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 2.3022 - accuracy: 0.1112 - val_loss: 2.3034 - val_accuracy: 0.1060\n",
      "Epoch 11/12\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 2.3022 - accuracy: 0.1125 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 12/12\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 2.3021 - accuracy: 0.1127 - val_loss: 2.3031 - val_accuracy: 0.1060\n"
     ]
    }
   ],
   "source": [
    "mnist_cnn_model_history = mnist_cnn_model.fit(X_train , y_train , epochs=12  , batch_size = 50 , validation_split = 0.2 , verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "q1tJARHSxbmW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17/313 [>.............................] - ETA: 1s - loss: 2.2980 - accuracy: 0.1324"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 13:11:45.868269: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 2.3016 - accuracy: 0.1135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.301569938659668, 0.11350000649690628]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_cnn_model_eval = mnist_cnn_model.evaluate(X_test, y_test)\n",
    "mnist_cnn_model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "lcWnY97IxbrG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 저장\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 13:11:48.069949: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-case.h12/assets\n"
     ]
    }
   ],
   "source": [
    "print('모델 저장')\n",
    "mnist_cnn_model.save('model-case.h12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "XPV6nP-Q3Juz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 복원\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m모델 복원\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel-case.h12\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "print('모델 복원')\n",
    "loaded_model = load_model('model-case.h12')\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXZgZYJi3Jxa"
   },
   "outputs": [],
   "source": [
    "loss , acc = loaded_model.evaluate(X_test , y_test)\n",
    "print('loss - ' , loss)\n",
    "print('acc  - ' , acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 분류 (horse-or-human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "print('데이터 세트 경로 - ')\n",
    "train_horse_dir = '/Users/book/Downloads/horse-or-human/horses'\n",
    "train_human_dir = '/Users/book/Downloads/horse-or-human/humans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horse_fileName = os.listdir(train_horse_dir)\n",
    "train_human_fileName = os.listdir(train_human_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horse_fileName[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_human_fileName[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('총 이미지 갯수 - ')\n",
    "print('horse len - ' , len(train_horse_fileName))\n",
    "print('human len - ' , len(train_human_fileName))\n",
    "\n",
    "# 'C:/Users/crid2/ml-data/horse-or-human' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_generator = ImageDataGenerator(rescale=1/255)\n",
    "train_generator = train_img_generator.flow_from_directory(\n",
    "    '/Users/book/Downloads/horse-or-human' , \n",
    "    target_size = (300, 300) , \n",
    "    batch_size  = 128 ,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_model() :\n",
    "  img_model = Sequential()\n",
    "\n",
    "  img_model.add( Conv2D(input_shape = (300, 300, 3) , filters = 16 , kernel_size = (3,3) , strides = (1,1) , padding = 'valid') )\n",
    "  img_model.add( Activation('relu'))\n",
    "  img_model.add( MaxPooling2D(pool_size = (2,2) , padding = 'valid' ) )\n",
    "  img_model.add( Dropout(0.25) )\n",
    "      \n",
    "  img_model.add( Conv2D(filters = 32 , kernel_size = (3,3) , strides = (1,1) , padding = 'valid') )\n",
    "  img_model.add( Activation('relu'))\n",
    "  img_model.add( MaxPooling2D(pool_size = (2,2) , padding = 'valid' ) )\n",
    "  img_model.add( Dropout(0.25) )\n",
    "\n",
    "  img_model.add( Conv2D(filters = 64 , kernel_size = (3,3) , strides = (1,1) , padding = 'valid') )\n",
    "  img_model.add( Activation('relu'))\n",
    "  img_model.add( MaxPooling2D(pool_size = (2,2) , padding = 'valid' ) )\n",
    "  img_model.add( Dropout(0.25) )\n",
    "\n",
    "  img_model.add( Conv2D(filters = 64 , kernel_size = (3,3) , strides = (1,1) , padding = 'valid') )\n",
    "  img_model.add( Activation('relu'))\n",
    "  img_model.add( MaxPooling2D(pool_size = (2,2) , padding = 'valid' ) )\n",
    "  img_model.add( Dropout(0.25) )\n",
    "\n",
    "  img_model.add( Flatten() )\n",
    "  img_model.add( Dense(units = 512) )\n",
    "  img_model.add( Activation('relu') )\n",
    "  img_model.add( Dropout(0.25) )\n",
    "  \n",
    "  img_model.add( Dense(units = 1) )\n",
    "  img_model.add( Activation('sigmoid') )\n",
    "\n",
    "  return img_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = img_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = RMSprop(lr = 0.001), \n",
    "                      loss= 'binary_crossentropy' , \n",
    "                      metrics=['accuracy'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(train_generator , epochs = 15 , verbose = 1 , steps_per_epoch = 8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "upload_img = files.upload()\n",
    "print(upload_img)\n",
    "print(upload_img.keys())\n",
    "\n",
    "for fn in upload_img.keys() :\n",
    "  print('file name - ' , fn )\n",
    "  path = '/content/'+fn\n",
    "  img = image.load_img(path , target_size = (300, 300))\n",
    "  x   = image.img_to_array(img) \n",
    "  x   = np.expand_dims(x , axis = 0 ) \n",
    "  image_ = np.vstack([x])\n",
    "\n",
    "  classes = model.predict(image_ , batch_size = 10 ) \n",
    "  print('pred - ' , classes[0])\n",
    "print('예측하기 - ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate \\\n",
    "https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "-O /downloads/cats_and_dogs_filtered.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고양이 개 이미지 분류 실습하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "path = '/Users/book/Downloads/cats_and_dogs_filtered.zip' \n",
    "zip  = zipfile.ZipFile(path , 'r')\n",
    "\n",
    "zip.extractall('/Users/book/Downloads/')\n",
    "zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_image = '/Users/book/Downloads/cats_and_dogs_filtered/train/cats/'\n",
    "dog_image = '/Users/book/Downloads/cats_and_dogs_filtered/train/dogs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_img_generator = ImageDataGenerator(rescale=1/255)\n",
    "train_generator = train_img_generator.flow_from_directory(\n",
    "    '/Users/book/Downloads/cats_and_dogs_filtered/train/' , \n",
    "    target_size = (300, 300) , \n",
    "    batch_size  = 128 ,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNExk2q6OmR56uP23IiPkZh",
   "include_colab_link": true,
   "name": "Untitled4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
